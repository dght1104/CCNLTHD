{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11589337,"sourceType":"datasetVersion","datasetId":7266695}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D,BatchNormalization,Cropping2D\nfrom tensorflow.keras.models import Model\nimport random\nimport tensorflow as tf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đọc tệp Excel vào DataFrame\nfile_path = \"/kaggle/input/btxrd-final/classification/classification.xlsx\"  # Đường dẫn đến file Excel\ndf = pd.read_excel(file_path)\n\n# Đường dẫn thư mục ảnh và mask\nimage_path = '/kaggle/input/btxrd-final/classification/images'\nmask_path = '/kaggle/input/btxrd-final/classification/masks'\nprint(\"dfasdfd\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Lọc những ảnh có mask\ndf_with_mask = df[df['mask_flag'] == 1]\n\n# Chia train, test, valid\ndf_train = df_with_mask[df_with_mask['tumor_category'] == 1].copy()\ndf_test  = df_with_mask[df_with_mask['tumor_category'] == 2].copy()\ndf_valid = df_with_mask[df_with_mask['tumor_category'] == 3].copy()\nprint(\"dfasdfd\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tạo cột đường dẫn\ndf_train['image_path'] = df_train['image_id'].apply(lambda x: os.path.join(image_path, f\"{os.path.splitext(x)[0]}.jpg\"))\ndf_train['mask_path']  = df_train['image_id'].apply(lambda x: os.path.join(mask_path, f\"{os.path.splitext(x)[0]}.png\"))\n\ndf_test['image_path'] = df_test['image_id'].apply(lambda x: os.path.join(image_path, f\"{os.path.splitext(x)[0]}.jpg\"))\ndf_test['mask_path']  = df_test['image_id'].apply(lambda x: os.path.join(mask_path, f\"{os.path.splitext(x)[0]}.png\"))\n\ndf_valid['image_path'] = df_valid['image_id'].apply(lambda x: os.path.join(image_path, f\"{os.path.splitext(x)[0]}.jpg\"))\ndf_valid['mask_path']  = df_valid['image_id'].apply(lambda x: os.path.join(mask_path, f\"{os.path.splitext(x)[0]}.png\"))\n\nprint(\"dfasdfd\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hàm load ảnh và mask\ndef load_image_and_mask(image_path, mask_path):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=1)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    \n    mask = tf.io.read_file(mask_path)\n    mask = tf.image.decode_png(mask, channels=1)\n    mask = tf.image.convert_image_dtype(mask, tf.float32)\n    \n    image = tf.image.resize(image, (224, 224))\n    mask = tf.image.resize(mask, (224, 224))\n    return image, mask\n\n# Chọn batch size random trước\nBATCH_SIZE = random.choice([8, 16, 32, 64])\n\n# Tạo datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((df_train['image_path'], df_train['mask_path']))\ntrain_dataset = train_dataset.map(load_image_and_mask)\ntrain_dataset = train_dataset.shuffle(buffer_size=1000)\ntrain_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\nval_dataset = tf.data.Dataset.from_tensor_slices((df_valid['image_path'], df_valid['mask_path']))\nval_dataset = val_dataset.map(load_image_and_mask)\nval_dataset = val_dataset.batch(16).prefetch(tf.data.AUTOTUNE)\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((df_test['image_path'], df_test['mask_path']))\ntest_dataset = test_dataset.map(load_image_and_mask)\ntest_dataset = test_dataset.batch(16).prefetch(tf.data.AUTOTUNE)\nprint(\"dfasdfd\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Kiểm tra một batch từ train_dataset\nfor images, masks in train_dataset.take(1):  # Lấy 1 batch từ train_dataset\n    print(\"Train batch shape:\")\n    print(\"Image batch shape:\", images.shape)  # Kích thước của batch ảnh\n    print(\"Mask batch shape:\", masks.shape)    # Kích thước của batch mask\n\n    # Hiển thị một ảnh và mask\n    plt.figure(figsize=(10, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.imshow(images[0, :, :, 0], cmap='gray')  # Hiển thị ảnh đầu tiên trong batch (1 channel)\n    plt.title(\"Sample Input Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(masks[0, :, :, 0], cmap='gray')  # Hiển thị mask đầu tiên trong batch (1 channel)\n    plt.title(\"Sample Mask\")\n    plt.axis('off')\n\n    plt.show()\n    break  # Dừng sau khi đã kiểm tra 1 batch\n\n# Kiểm tra một batch từ val_dataset\nfor images, masks in val_dataset.take(1):\n    print(\"Validation batch shape:\")\n    print(\"Image batch shape:\", images.shape)\n    print(\"Mask batch shape:\", masks.shape)\n\n    plt.figure(figsize=(10, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.imshow(images[0, :, :, 0], cmap='gray')\n    plt.title(\"Sample Input Image (Validation)\")\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(masks[0, :, :, 0], cmap='gray')\n    plt.title(\"Sample Mask (Validation)\")\n    plt.axis('off')\n\n    plt.show()\n    break\n\n# Kiểm tra một batch từ test_dataset\nfor images, masks in test_dataset.take(1):\n    print(\"Test batch shape:\")\n    print(\"Image batch shape:\", images.shape)\n    print(\"Mask batch shape:\", masks.shape)\n\n    plt.figure(figsize=(10, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.imshow(images[0, :, :, 0], cmap='gray')\n    plt.title(\"Sample Input Image (Test)\")\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(masks[0, :, :, 0], cmap='gray')\n    plt.title(\"Sample Mask (Test)\")\n    plt.axis('off')\n\n    plt.show()\n    break\nprint(\"dfasdfd\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\n\n# Mở ảnh\nimage = Image.open('/kaggle/input/btxrd-final/classification/masks/IMG000001.png')\n\n# Lấy kích thước ảnh (width, height)\nwidth, height = image.size\nprint(f\"Width: {width}, Height: {height}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unet_model(input_shape=(224, 224, 1), num_classes=1, num_levels=4, initial_filters=64):\n    \"\"\"\n    Tạo mô hình U-Net với số cấp độ (num_levels) và số lượng filters ban đầu (initial_filters).\n    \"\"\"\n    def conv_block(x, filters):\n        \"\"\"Tạo một block convolution gồm 2 lớp Conv2D với kích thước kernel (3, 3) và activation 'relu'.\"\"\"\n        x = layers.Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n        x = layers.Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n        return x\n\n    def encoder_block(x, filters):\n        \"\"\"Tạo một block Encoder gồm Conv2D và MaxPooling2D.\"\"\"\n        x = conv_block(x, filters)\n        pool = layers.MaxPooling2D((2, 2))(x)  # MaxPooling giảm kích thước ảnh\n        return x, pool\n\n    def decoder_block(x, skip, filters):\n        \"\"\"Tạo một block Decoder gồm UpSampling và kết hợp với skip connection.\"\"\"\n        up = layers.UpSampling2D((2, 2))(x)  # Upsample để khôi phục kích thước\n        merge = layers.concatenate([up, skip])  # Kết hợp với skip connection từ Encoder\n        x = conv_block(merge, filters)  # Thực hiện convolution sau khi kết hợp\n        return x\n\n    # Input layer\n    inputs = layers.Input(shape=input_shape)\n    skips = []  # List lưu các skip connection (kết nối từ các tầng encoder)\n    x = inputs\n    filters = initial_filters\n\n    # Encoder: Các lớp Conv2D và MaxPooling2D\n    for _ in range(num_levels):\n        conv, pool = encoder_block(x, filters)\n        skips.append(conv)  # Lưu lại các skip connection\n        x = pool\n        filters *= 2  # Tăng số lượng filters sau mỗi cấp độ\n\n    # Bottleneck: Block giữa encoder và decoder\n    x = conv_block(x, filters)\n\n    # Decoder: Các lớp Upsample và Conv2D với skip connection\n    filters //= 2  # Giảm số lượng filters\n    for skip in reversed(skips):\n        x = decoder_block(x, skip, filters)\n        filters //= 2  # Giảm số lượng filters\n\n    # Output layer: Lớp cuối với kích thước 1x1 để tạo ra số lớp phân loại\n    outputs = layers.Conv2D(num_classes, (1, 1), activation='sigmoid')(x)\n\n    # Tạo mô hình\n    model = models.Model(inputs, outputs)\n    \n    return model\n\n# Tạo mô hình U-Net với 4 cấp độ và số lượng filters ban đầu là 32\nmodel = unet_model(num_levels=4, initial_filters=32)\nmodel.summary()\n\n# Bạn có thể tạo mô hình với số cấp độ khác nhau\n# model_5_levels = unet_model(num_levels=5, initial_filters=16)\n# model_5_levels.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport tensorflow as tf\n\n# Định nghĩa mô hình\nmodel = unet_model()\n\n# Compile mô hình với metrics phù hợp hơn\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=2)])  # Giả sử 2 lớp (nền và đối tượng)\n\n# Định nghĩa callbacks\ncheckpoint_filepath = 'unet_best_model.keras'  # Đổi tên thành .keras\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_best_only=True,\n    monitor='val_mean_io_u',  # Theo dõi IoU trên tập validation\n    mode='max')\n\nearly_stopping_callback = EarlyStopping(\n    monitor='val_mean_io_u',  # Theo dõi IoU trên tập validation\n    patience=10,\n    mode='max',\n    restore_best_weights=True)\n\nreduce_lr_callback = ReduceLROnPlateau(\n    monitor='val_mean_io_u',  # Theo dõi IoU trên tập validation\n    factor=0.1,\n    patience=5,\n    min_lr=0.00001)\n\ncallbacks = [model_checkpoint_callback, early_stopping_callback, reduce_lr_callback]\n\n# Huấn luyện mô hình với callbacks\nhistory = model.fit(\n    train_dataset,\n    epochs=50,\n    validation_data=val_dataset,\n    verbose=1,\n    callbacks=callbacks\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = model.evaluate(test_dataset)\nprint(f\"Results: {results}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dự đoán trên test dataset và hiển thị kết quả\nfor image_batch, mask_batch in test_dataset.take(1):  # Chỉ lấy một batch từ test dataset\n    pred_batch = model.predict(image_batch)  # Dự đoán cho batch\n    pred_batch = (pred_batch > 0.5).astype(np.float32)  # Chuyển sang nhị phân (0 hoặc 1)\n\n    # Hiển thị ảnh gốc, mask thực tế và mask dự đoán\n    plt.figure(figsize=(12, 12))\n    for i in range(min(4, len(image_batch))):  # Chỉ hiển thị 4 ảnh đầu tiên\n        # Ảnh gốc\n        plt.subplot(4, 3, i * 3 + 1)\n        plt.imshow(image_batch[i, :, :, 0], cmap='gray')\n        plt.title(\"Image\")\n        plt.axis('off')\n\n        # Mask thực tế\n        plt.subplot(4, 3, i * 3 + 2)\n        plt.imshow(mask_batch[i, :, :, 0], cmap='gray')\n        plt.title(\"True Mask\")\n        plt.axis('off')\n\n        # Mask dự đoán\n        plt.subplot(4, 3, i * 3 + 3)\n        plt.imshow(pred_batch[i, :, :, 0], cmap='gray')\n        plt.title(\"Predicted Mask\")\n        plt.axis('off')\n\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('unet_model.h5')  # Lưu mô hình dưới dạng file .h5\nmodel.save('/kaggle/working/unet_model.h5')  # Lưu mô hình vào thư mục /kaggle/working","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Tạo liên kết tải xuống cho file mô hình\nFileLink('/kaggle/working/unet_model.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}