{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12810295,"sourceType":"datasetVersion","datasetId":8100280}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =======================\n# 0) Imports & Config\n# =======================\nimport os, cv2, random, numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom datetime import datetime\nfrom zoneinfo import ZoneInfo\nfrom scipy.ndimage import distance_transform_edt\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Dropout, Concatenate\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.utils import plot_model\n\nimport wandb\nfrom wandb.integration.keras import WandbCallback\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:37:00.555994Z","iopub.execute_input":"2025-08-19T18:37:00.556303Z","iopub.status.idle":"2025-08-19T18:37:22.407730Z","shell.execute_reply.started":"2025-08-19T18:37:00.556279Z","shell.execute_reply":"2025-08-19T18:37:22.406810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hyperparams\nIMG_SIZE = 512\nBATCH_SIZE = 4\nEPOCH = 350\nlearning_rate = 1e-4\nweight_decay = 1e-5\noptimizer = tf.keras.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay)\n\n# Paths\nfile_path = \"/kaggle/input/d/hntrnnggia/btxrd-v1/classification.xlsx\"\nimage_path = \"/kaggle/input/d/hntrnnggia/btxrd-v1/images\"\nmask_path  = \"/kaggle/input/d/hntrnnggia/btxrd-v1/masks\"\ndist_map_save_path = \"/kaggle/working/distance_maps/\"\nos.makedirs(dist_map_save_path, exist_ok=True)\n\nprint(\"==> Load Excel\")\ndf = pd.read_excel(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:37:22.409110Z","iopub.execute_input":"2025-08-19T18:37:22.409604Z","iopub.status.idle":"2025-08-19T18:37:23.989746Z","shell.execute_reply.started":"2025-08-19T18:37:22.409583Z","shell.execute_reply":"2025-08-19T18:37:23.988475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================\n# 1) Distance Map Builder\n# =======================\ndef create_distance_map_np(mask_np):\n    binary_mask = (mask_np > 0).astype(np.uint8)\n    fg = binary_mask\n    bg = 1 - fg\n    dist_out = distance_transform_edt(bg)\n    dist_in  = distance_transform_edt(fg)\n    dist_map = dist_out - dist_in\n    max_val = np.max(np.abs(dist_map))\n    if max_val > 0: \n        dist_map = dist_map / max_val\n    return dist_map.astype(np.float32)\n\ndf_with_mask = df[df[\"mask_flag\"]==1].copy()\nprint(f\"Tạo & lưu distance maps cho {len(df_with_mask)} ảnh...\")\nfor _, row in tqdm(df_with_mask.iterrows(), total=df_with_mask.shape[0]):\n    image_id = row[\"image_id\"]\n    base = os.path.splitext(image_id)[0]\n    cur_mask_path = os.path.join(mask_path, f\"{base}.png\")\n    mask_img = cv2.imread(cur_mask_path, cv2.IMREAD_GRAYSCALE)\n    if mask_img is None: \n        continue\n    mask_img = cv2.resize(mask_img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n    dist_map = create_distance_map_np(mask_img)\n    np.save(os.path.join(dist_map_save_path, f\"{base}.npy\"), dist_map)\nprint(f\"✅ Tiền xử lý xong. Saved at: {dist_map_save_path}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:37:23.990851Z","iopub.execute_input":"2025-08-19T18:37:23.991439Z","iopub.status.idle":"2025-08-19T18:39:17.244303Z","shell.execute_reply.started":"2025-08-19T18:37:23.991402Z","shell.execute_reply":"2025-08-19T18:39:17.243407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================\n# 2) Split & Path Columns\n# =======================\ndf_t = df[df[\"mask_flag\"]==1].copy()\ndf_train, df_temp = train_test_split(df_t, test_size=0.3, random_state=42, shuffle=True, stratify=df_t[\"tumor_type\"])\ndf_valid, df_test = train_test_split(df_temp, test_size=0.5, random_state=42, shuffle=True, stratify=df_temp[\"tumor_type\"])\nprint(\"Split sizes -> Train:\", len(df_train), \"Valid:\", len(df_valid), \"Test:\", len(df_test))\n\ndef add_paths(df_):\n    base_name = lambda x: os.path.splitext(x)[0]\n    df_ = df_.copy()\n    df_[\"image_path\"] = df_[\"image_id\"].apply(lambda x: os.path.join(image_path, f\"{base_name(x)}.jpg\"))\n    df_[\"mask_path\"]  = df_[\"image_id\"].apply(lambda x: os.path.join(mask_path,  f\"{base_name(x)}.png\"))\n    df_[\"dist_map_path\"] = df_[\"image_id\"].apply(lambda x: os.path.join(dist_map_save_path, f\"{base_name(x)}.npy\"))\n    return df_\n\ndf_train = add_paths(df_train)\ndf_valid = add_paths(df_valid)\ndf_test  = add_paths(df_test)\nprint(\"==> Added paths columns\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:39:17.246289Z","iopub.execute_input":"2025-08-19T18:39:17.246805Z","iopub.status.idle":"2025-08-19T18:39:17.287216Z","shell.execute_reply.started":"2025-08-19T18:39:17.246782Z","shell.execute_reply":"2025-08-19T18:39:17.286298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================\n# 3) TF Datasets (Fixed)\n# =======================\ndef load_dist_map(dist_map_path):\n    def _load(path):\n        path = path.decode()  # numpy_function luôn truyền vào bytes\n        arr = np.load(path).astype(np.float32)\n        return arr\n    dist = tf.numpy_function(_load, [dist_map_path], tf.float32)\n    dist.set_shape([IMG_SIZE, IMG_SIZE])\n    dist = tf.expand_dims(dist, -1)  # [H, W, 1]\n    return dist\n\ndef load_image_and_mask(image_path, mask_path):\n    img_bytes = tf.io.read_file(image_path)\n    image = tf.io.decode_image(img_bytes, channels=1, expand_animations=False)\n    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n    image = tf.cast(image, tf.float32)/255.0\n\n    mask_bytes = tf.io.read_file(mask_path)\n    mask = tf.io.decode_image(mask_bytes, channels=1, expand_animations=False)\n    mask = tf.image.resize(mask, [IMG_SIZE, IMG_SIZE], method='nearest')\n    mask = tf.cast(mask > 0, tf.uint8)\n    mask = tf.squeeze(mask, axis=-1)          # [H, W]\n    mask = tf.one_hot(mask, depth=2)          # [H, W, 2]\n    mask = tf.cast(mask, tf.float32)\n    return image, mask\n\ndef augment_image_mask(image, mask):\n    if tf.random.uniform(()) > 0.5: \n        image, mask = tf.image.flip_left_right(image), tf.image.flip_left_right(mask)\n    if tf.random.uniform(()) > 0.5: \n        image = tf.image.random_brightness(image, 0.1)\n    if tf.random.uniform(()) > 0.5: \n        image = tf.image.random_contrast(image, 0.8, 1.2)\n    image = tf.clip_by_value(image, 0.0, 1.0)\n    return image, mask\n\ndef load_all_data(image_path, mask_path, dist_map_path):\n    image, mask = load_image_and_mask(image_path, mask_path)\n    distance_map = load_dist_map(dist_map_path)\n    return image, {'mask_output': mask, 'distance_output': distance_map}\n\ndef load_all_data_with_aug(image_path, mask_path, dist_map_path):\n    image, mask = load_image_and_mask(image_path, mask_path)\n    image, mask = augment_image_mask(image, mask)\n    distance_map = load_dist_map(dist_map_path)\n    return image, {'mask_output': mask, 'distance_output': distance_map}\n\ndef make_ds(df_, aug=False, batch=BATCH_SIZE, shuffle=True):\n    ds = tf.data.Dataset.from_tensor_slices(\n        (df_[\"image_path\"].values, df_[\"mask_path\"].values, df_[\"dist_map_path\"].values)\n    )\n    map_fn = load_all_data_with_aug if aug else load_all_data\n    ds = ds.map(map_fn, num_parallel_calls=tf.data.AUTOTUNE)\n    if shuffle: \n        ds = ds.shuffle(500)\n    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n    return ds\n\ntrain_dataset = make_ds(df_train, aug=True)\nval_dataset   = make_ds(df_valid, aug=False, batch=BATCH_SIZE*2, shuffle=False)\ntest_dataset  = make_ds(df_test, aug=False, batch=BATCH_SIZE*2, shuffle=False)\nprint(\"==> Datasets ready\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:39:17.288091Z","iopub.execute_input":"2025-08-19T18:39:17.288531Z","iopub.status.idle":"2025-08-19T18:39:17.785189Z","shell.execute_reply.started":"2025-08-19T18:39:17.288502Z","shell.execute_reply":"2025-08-19T18:39:17.784415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================\n# 4) Sanity check & viz\n# =======================\nfor images, labels in train_dataset.take(1):\n    print(\"Train batch shapes:\", images.shape, labels['mask_output'].shape, labels['distance_output'].shape)\n    plt.figure(figsize=(12,4))\n    plt.subplot(1,3,1); plt.imshow(images[0,...,0], cmap='gray'); plt.title(\"Image\"); plt.axis('off')\n    plt.subplot(1,3,2); plt.imshow(labels['mask_output'][0,...,1], cmap='gray'); plt.title(\"Mask (FG)\"); plt.axis('off')\n    plt.subplot(1,3,3); plt.imshow(labels['distance_output'][0,...,0], cmap='gray'); plt.title(\"Distance Map\"); plt.axis('off')\n    plt.show()\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:39:17.786075Z","iopub.execute_input":"2025-08-19T18:39:17.786343Z","iopub.status.idle":"2025-08-19T18:39:22.523631Z","shell.execute_reply.started":"2025-08-19T18:39:17.786306Z","shell.execute_reply":"2025-08-19T18:39:22.522545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================\n# 5) Model\n# =======================\ndef segnet_multitask(input_shape=(512, 512, 1), num_classes=2):\n    def conv_block(x, filters, dropout_rate=0.0):\n        x = Conv2D(filters, 3, activation='relu', padding='same')(x)\n        x = BatchNormalization()(x)\n        if dropout_rate > 0:\n            x = Dropout(dropout_rate)(x)\n        x = Conv2D(filters, 3, activation='relu', padding='same')(x)\n        x = BatchNormalization()(x)\n        return x\n\n    inputs = Input(shape=input_shape)\n\n    # Encoder\n    c1 = conv_block(inputs, 32)\n    p1 = MaxPooling2D()(c1)\n\n    c2 = conv_block(p1, 64)\n    p2 = MaxPooling2D()(c2)\n\n    c3 = conv_block(p2, 128, 0.3)\n    p3 = MaxPooling2D()(c3)\n\n    c4 = conv_block(p3, 256, 0.3)\n    p4 = MaxPooling2D()(c4)\n\n    # Bottleneck\n    bn = conv_block(p4, 512, 0.4)\n\n    # Decoder + skip connections (không crop nữa)\n    u4 = UpSampling2D()(bn)\n    u4 = Concatenate()([u4, c4])\n    c5 = conv_block(u4, 256, 0.3)\n\n    u3 = UpSampling2D()(c5)\n    u3 = Concatenate()([u3, c3])\n    c6 = conv_block(u3, 128, 0.3)\n\n    u2 = UpSampling2D()(c6)\n    u2 = Concatenate()([u2, c2])\n    c7 = conv_block(u2, 64)\n\n    u1 = UpSampling2D()(c7)\n    u1 = Concatenate()([u1, c1])\n    c8 = conv_block(u1, 32)\n\n    # Multi-task outputs\n    mask_out = Conv2D(num_classes, 1, activation='softmax', name='mask_output')(c8)\n    dist_out = Conv2D(1, 1, activation='tanh', name='distance_output')(c8)\n\n    return Model(inputs, [mask_out, dist_out])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:39:22.524629Z","iopub.execute_input":"2025-08-19T18:39:22.524867Z","iopub.status.idle":"2025-08-19T18:39:22.535216Z","shell.execute_reply.started":"2025-08-19T18:39:22.524848Z","shell.execute_reply":"2025-08-19T18:39:22.534183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================\n# 6) Loss & metrics\n# =======================\ndef weighted_dice_loss(y_true, y_pred, class_weights=[0.5,0.5], smooth=1e-6):\n    loss = 0.0\n    for i,w in enumerate(class_weights):\n        yt = K.flatten(y_true[...,i]); yp = K.flatten(y_pred[...,i])\n        inter = K.sum(yt*yp); union = K.sum(yt)+K.sum(yp)\n        loss += w*(1-(2*inter+smooth)/(union+smooth))\n    return loss\n\ndef dice_coef(y_true, y_pred, smooth=1e-6):\n    y_pred_hard = tf.one_hot(tf.argmax(y_pred, axis=-1), depth=tf.shape(y_pred)[-1])\n    inter = K.sum(y_true*y_pred_hard)\n    union = K.sum(y_true)+K.sum(y_pred_hard)\n    return (2*inter+smooth)/(union+smooth)\n\ndef iou_binary_from_onehot(y_true, y_pred, smooth=1e-6):\n    y_true_fg = y_true[...,1]; y_pred_fg = tf.cast(tf.argmax(y_pred,axis=-1)==1,tf.float32)\n    inter = tf.reduce_sum(y_true_fg*y_pred_fg)\n    union = tf.reduce_sum(y_true_fg)+tf.reduce_sum(y_pred_fg)-inter\n    return (inter+smooth)/(union+smooth)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:39:22.536349Z","iopub.execute_input":"2025-08-19T18:39:22.536636Z","iopub.status.idle":"2025-08-19T18:39:22.560464Z","shell.execute_reply.started":"2025-08-19T18:39:22.536614Z","shell.execute_reply":"2025-08-19T18:39:22.559428Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 7) Build model\n# =======================\nmodel = segnet_multitask(input_shape=(IMG_SIZE,IMG_SIZE,1))\nplot_model(model, to_file='/kaggle/working/segnet_multitask_light.png', \n           show_shapes=True, show_layer_names=True)\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:39:22.561351Z","iopub.execute_input":"2025-08-19T18:39:22.561592Z","iopub.status.idle":"2025-08-19T18:39:27.466960Z","shell.execute_reply.started":"2025-08-19T18:39:22.561574Z","shell.execute_reply":"2025-08-19T18:39:27.466163Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ======================\n# 1. Config thời gian & wandb\n# ======================\nnow_vn = datetime.now(ZoneInfo(\"Asia/Ho_Chi_Minh\"))\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nos.environ[\"WANDB_API_KEY\"] = \"0cc72a0b4220798e1847f8b28354bbd46e441792\"  # API key\n\nprj_name = \"Unet_Distance_\" + now_vn.strftime(\"%H:%M_%d/%m/%Y\")\n\nwandb.login()\nwandb.init(\n    project=\"SegNet_Multitask\",\n    name=prj_name,\n    entity=\"unet-projects\",\n    config={\n        \"epochs\": EPOCH,\n        \"learning_rate\": learning_rate,\n        \"weight_decay\": weight_decay,\n        \"architecture\": \"SegNet-Multitask\",\n        \"input_shape\": (512, 512, 1),\n        \"num_classes\": 2,\n        \"batch_size\": BATCH_SIZE,\n        \"optimizer\": \"Adam\",\n        \"loss_mask\": \"weighted_dice_loss\",\n        \"loss_distance\": \"mse\",\n        \"loss_weights\": {\n            \"mask_output\": 1.0,\n            \"distance_output\": 0.5\n        },\n        \"metrics_mask\": [\"dice_coef\", \"iou_binary_from_onehot\"],\n        \"metrics_distance\": [\"mse\"],\n        \"dataset\": \"BTXRD\"\n    }\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:39:27.469485Z","iopub.execute_input":"2025-08-19T18:39:27.469786Z","iopub.status.idle":"2025-08-19T18:39:41.998824Z","shell.execute_reply.started":"2025-08-19T18:39:27.469764Z","shell.execute_reply":"2025-08-19T18:39:41.997724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================\n# 2. Compile model\n# ======================\nmodel.compile(\n    optimizer=optimizer,\n    loss={\n        \"mask_output\": weighted_dice_loss,\n        \"distance_output\": \"mse\"\n    },\n    loss_weights={\n        \"mask_output\": 1.0,\n        \"distance_output\": 0.5\n    },\n    metrics={\n        \"mask_output\": [dice_coef, iou_binary_from_onehot],\n        \"distance_output\": [\"mse\"]\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:39:41.999879Z","iopub.execute_input":"2025-08-19T18:39:42.000191Z","iopub.status.idle":"2025-08-19T18:39:42.013072Z","shell.execute_reply.started":"2025-08-19T18:39:42.000161Z","shell.execute_reply":"2025-08-19T18:39:42.011947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================\n# 3. Custom callback log ảnh mask lên wandb\n# ======================\nclass WandbImageLogger(tf.keras.callbacks.Callback):\n    def __init__(self, val_dataset, num_samples=3):\n        super().__init__()\n        self.samples = list(val_dataset.unbatch().take(num_samples))\n\n    def on_epoch_end(self, epoch, logs=None):\n        images = []\n        for img, (mask, dist) in self.samples:\n            img_np = img.numpy()\n            true_mask = np.argmax(mask.numpy(), axis=-1) if mask.shape[-1] > 1 else mask.numpy().squeeze()\n            \n            pred = self.model.predict(img[None, ...], verbose=0)\n            pred_mask = np.argmax(pred[0], axis=-1).squeeze()\n\n            images.append(\n                wandb.Image(\n                    img_np.squeeze(),\n                    caption=f\"Epoch {epoch+1}\",\n                    masks={\n                        \"true\": {\"mask_data\": true_mask},\n                        \"pred\": {\"mask_data\": pred_mask}\n                    }\n                )\n            )\n        wandb.log({\"Examples\": images}, step=epoch)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:39:42.014165Z","iopub.execute_input":"2025-08-19T18:39:42.014448Z","iopub.status.idle":"2025-08-19T18:39:42.026488Z","shell.execute_reply.started":"2025-08-19T18:39:42.014428Z","shell.execute_reply":"2025-08-19T18:39:42.025233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================\n# 4. Callbacks\n# ======================\nmodel_checkpoint = ModelCheckpoint(\n    \"/kaggle/working/segnet_best.keras\", monitor=\"val_loss\", save_best_only=True, verbose=1\n)\nearly_stopping = EarlyStopping(\n    monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1\n)\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"val_loss\", factor=0.2, patience=5, min_lr=1e-7, verbose=1\n)\nwandb_cb = WandbCallback(save_model=True, save_graph=False)\nwandb_img_logger = WandbImageLogger(val_dataset, num_samples=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:39:42.027627Z","iopub.execute_input":"2025-08-19T18:39:42.027913Z","iopub.status.idle":"2025-08-19T18:39:42.361739Z","shell.execute_reply.started":"2025-08-19T18:39:42.027894Z","shell.execute_reply":"2025-08-19T18:39:42.360767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================\n# 5. Fit model\n# ======================\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=EPOCH,\n    callbacks=[model_checkpoint, early_stopping, reduce_lr, wandb_cb, wandb_img_logger],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:39:42.362698Z","iopub.execute_input":"2025-08-19T18:39:42.362942Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Config**","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(test_dataset)\nprint(\"📊 Test results:\", results)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}